{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "from ultralytics import YOLO\n",
    "import csv\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # RealSenseのパイプラインをセットアップ\n",
    "        pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        \n",
    "        bag_file_path = '20240808_144616.bag'  # ここにbagファイルのパスを指定\n",
    "        config.enable_device_from_file(bag_file_path)\n",
    "        \n",
    "        pipeline.start(config)\n",
    "\n",
    "        # 再生速度を制御するためのplaybackオブジェクトを取得\n",
    "        playback = pipeline.get_active_profile().get_device().as_playback()\n",
    "        playback.set_real_time(False)  # リアルタイム再生を無効にする\n",
    "        \n",
    "        model = YOLO(\"model_fish.pt\")\n",
    "\n",
    "        frame_count = 0\n",
    "        detection_data = []  # 検出データを収集するリスト\n",
    "\n",
    "        # ビデオライターをセットアップ\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # コーデックを指定\n",
    "        out = cv2.VideoWriter('output.mov', fourcc, 30.0, (640, 480))  # 出力ファイル名、コーデック、フレームレート、フレームサイズ\n",
    "\n",
    "        while True:\n",
    "            # フレームのセットを取得\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            color_frame = frames.get_color_frame()\n",
    "        \n",
    "            if not depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            # 深度フレームとカラー（RGB）フレームをnumpy配列に変換\n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # RGB画像をBGRに変換\n",
    "            color_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # YOLOで物体検出\n",
    "            results = model.track(color_image, persist=True, show=False)\n",
    "            \n",
    "            for result in results:\n",
    "                if result.masks is not None and hasattr(result.masks, 'data'):  # result.masksがNoneでなく、data属性を持つことを確認\n",
    "                    for idx, mask in enumerate(result.masks.data):\n",
    "                        # マスクからピクセル数をカウント\n",
    "                        mask = mask.cpu().numpy()  # マスクをnumpy配列に変換\n",
    "                        pixel_count = np.count_nonzero(mask)\n",
    "\n",
    "                        distances = []\n",
    "\n",
    "                        for point in np.argwhere(mask):  # マスクの中のピクセル位置を取得\n",
    "                            y, x = point  # argwhereは(y, x)の順で返される\n",
    "                            if 0 <= x < depth_image.shape[1] and 0 <= y < depth_image.shape[0]:  # 座標の範囲チェック\n",
    "                                distance = depth_frame.get_distance(x, y)\n",
    "                                if not np.isnan(distance):  # NaNをチェック\n",
    "                                    distances.append(distance)\n",
    "\n",
    "                        if distances:\n",
    "                            avg_distance = np.mean(distances)\n",
    "                        else:\n",
    "                            avg_distance = 0\n",
    "\n",
    "                        # 検出結果を表示\n",
    "                        center_x = np.mean(np.argwhere(mask)[:, 1])\n",
    "                        center_y = np.mean(np.argwhere(mask)[:, 0])\n",
    "\n",
    "                        # NaNチェックを追加して整数に変換\n",
    "                        if np.isnan(center_x) or np.isnan(center_y):\n",
    "                            center_x, center_y = 0, 0\n",
    "                        else:\n",
    "                            center_x, center_y = int(center_x), int(center_y)\n",
    "\n",
    "                        label = f\"{avg_distance:.2f}m\"\n",
    "\n",
    "                        # 検出結果を保存\n",
    "                        if hasattr(result.boxes, 'id'):  # result.boxesがid属性を持つことを確認\n",
    "                            detection_id = result.boxes.id[idx] if idx < len(result.boxes.id) else -1\n",
    "                        else:\n",
    "                            detection_id = -1\n",
    "                        \n",
    "                        detection_id= str(detection_id)\n",
    "                        pattern = r'\\d+'\n",
    "                        detection_id_str= re.findall(pattern, detection_id)\n",
    "                        input_string = str(detection_id_str)\n",
    "                        detection_id_num = int(input_string.strip(\"[]'\"))\n",
    "                        detection_data.append([detection_id_num, frame_count, avg_distance, pixel_count])\n",
    "                        \n",
    "                        # テキストを描画\n",
    "                        cv2.putText(color_image, label, (center_x + 5, center_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                cv2.imshow(\"YOLOv8トラッキング\", results[0].plot())\n",
    "\n",
    "                # フレームを保存\n",
    "                frame_filename = f\"frame_{frame_count:04d}.png\"\n",
    "                cv2.imwrite(frame_filename, results[0].plot())\n",
    "                print(f\"Saved frame: {frame_filename}\")\n",
    "\n",
    "            # ビデオファイルにフレームを書き込む\n",
    "            out.write(results[0].plot())\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "            # 'q'キーを押したら終了\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # クリーンアップ\n",
    "        pipeline.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "        out.release()\n",
    "\n",
    "        # 検出データをCSVファイルに書き出し\n",
    "        csv_filename = 'detection_data.csv'\n",
    "        with open(csv_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Detection ID\", \"Frame\", \"Average Distance (m)\", \"Pixel Count\"])\n",
    "            writer.writerows(detection_data)\n",
    "        print(f\"Saved detection data to {csv_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# CSVファイルを読み込む\n",
    "df = pd.read_csv('detection_data.csv')\n",
    "\n",
    "# 'Average Distance (m)' が0でない行のみを残す\n",
    "df = df[df['Average Distance (m)'] != 0]\n",
    "\n",
    "# 固定値\n",
    "FOV_horizontal = 86  # 水平方向の視野角（度）\n",
    "FOV_vertical = 57    # 垂直方向の視野角（度）\n",
    "resolution_horizontal = 840  # 水平方向の解像度（ピクセル）\n",
    "resolution_vertical = 480    # 垂直方向の解像度（ピクセル）\n",
    "\n",
    "# 視野幅の計算\n",
    "# 水平方向の視野幅を計算\n",
    "df['W_horizontal'] = 2 * df['Average Distance (m)'] * math.tan(math.radians(FOV_horizontal / 2))\n",
    "# 垂直方向の視野幅を計算\n",
    "df['W_vertical'] = 2 * df['Average Distance (m)'] * math.tan(math.radians(FOV_vertical / 2))\n",
    "\n",
    "# 1ピクセルあたりの物理的な幅の計算\n",
    "df['pixel_width'] = df['W_horizontal'] / resolution_horizontal  # 水平方向\n",
    "df['pixel_height'] = df['W_vertical'] / resolution_vertical  # 垂直方向\n",
    "\n",
    "# 物体の物理的な大きさ（面積）を計算\n",
    "df['size'] = df['Pixel Count'] * df['pixel_width'] * df['pixel_height']\n",
    "\n",
    "# 'size' が0でない行でグループ化して平均を計算\n",
    "mean_pixel_counts = df[df['size'] != 0].groupby('Detection ID')['size'].mean()\n",
    "print(mean_pixel_counts)\n",
    "\n",
    "# ヒストグラムを計算\n",
    "bins = np.linspace(0, 2, 5)\n",
    "freq, _ = np.histogram(mean_pixel_counts, bins=bins)\n",
    "class_value = (bins[:-1] + bins[1:]) / 2  # 階級値\n",
    "rel_freq = freq / mean_pixel_counts.count()  # 相対度数\n",
    "cum_freq = np.cumsum(freq)  # 累積度数\n",
    "\n",
    "# データフレームに結果をまとめる\n",
    "dist = pd.DataFrame(\n",
    "    {\n",
    "        \"grade value\": class_value,\n",
    "        \"meter\": freq,\n",
    "        \"相対度数\": rel_freq,\n",
    "        \"累積度数\": cum_freq,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(dist)\n",
    "\n",
    "# 棒グラフをプロット\n",
    "dist.plot.bar(x=\"grade value\", y=\"meter\", width=1, ec=\"k\", lw=2)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
